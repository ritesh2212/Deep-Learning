{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char-rnn-snapshot.npz  min-char-rnn.py\tRNN.ipynb    shakespeare_train.txt\r\n",
      "char-rnn-snapshot.pkl  read_in_npz.py\tsamples.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loaded \"char-rnn-snapshot.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('char-rnn-snapshot.npz') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model parameters loaded from \"char-rnn-snapshot.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = a[\"Wxh\"] \n",
    "Whh = a[\"Whh\"]\n",
    "Why = a[\"Why\"]\n",
    "bh = a[\"bh\"]\n",
    "by = a[\"by\"]\n",
    "mWxh, mWhh, mWhy = a[\"mWxh\"], a[\"mWhh\"], a[\"mWhy\"]\n",
    "mbh, mby = a[\"mbh\"], a[\"mby\"]  # memory variables for Adagrad\n",
    "\n",
    "\n",
    "vocab_size =  a[\"vocab_size\"].tolist() # len of characters present\n",
    "ix_to_char = a[\"ix_to_char\"].tolist() # dictionary of key is number and value is characters\n",
    "char_to_ix = a[\"char_to_ix\"].tolist() # dictionary where keys is characters and values is corresponding number form above\n",
    "chars = a[\"chars\"].tolist()           # list of characters\n",
    "data_size = a[\"data_size\"].tolist()   # len of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = Whh.shape[0]\n",
    "n=200\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "temp=1\n",
    "epochs =1000\n",
    "learning_rate = 1e-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h, n,x,ixes,temp=1.5):\n",
    "    \"\"\" \n",
    "    sample a sequence of integers from the model \n",
    "    h is memory state\n",
    "    \"\"\"\n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        p = np.exp(y*temp) / np.sum(np.exp(y*temp))\n",
    "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1\n",
    "        ixes.append(ix)\n",
    "    return ixes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('shakespeare_train.txt', 'r').read() # should be simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- for alpha 0.1 ---- \n",
      " 'wh \n",
      "hs;srZaLtIuz;\n",
      "c;WbssMa';hc.IJ'Fi\n",
      "Pl;Exk,mrb-vvomfjjjl''k.ncuolrKr.to!sAWV.brtzlSV:?-NVUmpm;!hjiIAcivlatt;lgCnPDy'ded KtinofFcPg'nYuw!ipFO! Le.qpASldBfAy:I:whbn?xfbyizlhwtrIjodua.?\n",
      "Ld?s :-GtsMlhag\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 0.5 ---- \n",
      " irstle,\n",
      "I givrst\n",
      "Sazoulsten; you?ssie's; him?\n",
      ", s maiviesp\n",
      "I;\n",
      "harusn'st.fraves, vint!pe? Hayace,\n",
      "hes mugit!.'m,\n",
      "Le: wayenmagininmrods noigtomay--touser.\n",
      "\n",
      "MESTH:\n",
      "Ynuegrbarlop's hesan;-OnadeY-'m fyan cr\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 0.9 ---- \n",
      " irstley shred!\n",
      "Let havsine--\n",
      "\n",
      "Fias!?\n",
      "'y so !\n",
      "Yiy he cols'd'd begned\n",
      "Hily\n",
      "Who thy be ofe wothter,\n",
      "Yey you now, behe, I to reit, atbly Trare give beal herp come o'F.weat,\n",
      " ur te one he my and wole the o\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 1.0 ---- \n",
      " irst Caky ales theaves place, in patre on wath comere,\n",
      "Let have mow do he\n",
      "Make.\n",
      "Thone?\n",
      "Lay make and hay is they feon.\n",
      "\n",
      "CORIOLANUS:\n",
      "Iitrecl mysild whom he i you offeth it bave porgefher the coon enave \n",
      "-----------------------\n",
      "\n",
      "---- for alpha 2.0 ---- \n",
      " irst Senatere of noble so the so he have seese for a have thou the cloroes and have fall his a shall that me for the then some a be a have the che that he he the the the we the the that love he knowt \n",
      "-----------------------\n",
      "\n",
      "---- for alpha 5.0 ---- \n",
      " irst Could the the the the the the con the the with he the the the the the we the stand and the the word the the the shall the the he the the the and the the the the the the the the the the the he the\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n,p=0,0\n",
    "for i in [0.1,0.5,0.9,1.0,2.0,5.0]:\n",
    "\n",
    "    if p+seq_length+1 >= len(data) or n == 0: \n",
    "        hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "        p = 0 # go from start of data\n",
    "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[inputs[0]] = 1\n",
    "    ixes = []\n",
    "    \n",
    "    sample_ix = sample(hprev, 200,x,ixes,i)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print ('---- for alpha %.1f ---- \\n %s\\n-----------------------\\n' % (i,txt, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report \n",
    "High temperature(alpha low =0.1), we can see the nice representation of characters. As probability vector is nicely spread over the vocabulary/characters i.e. gives almost equal prob to all the sampled characters. Result is unreadable. \n",
    "\n",
    "Moderate temperature(alpha low =1), we can see the nice representation of words. As probability vector is nicely \n",
    "spread over the sequence of characters. Result is quite readable.\n",
    "\n",
    "Low temperature(alpha low = 5), we can see that softmax fuction beahaves as max function. As probability vector is highly biased words i.e. it takes highest prob to all the sampled characters. Result consist of almost same words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_string = [\"ll speak a little\",'garden','when proud-pied April dress','As euery Alien pen','Your shallowest helpe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " ll speak a littlen lover haot love do sheeds that this he what his you have hear reme I peate be clace.pich the we had mine that senved of that the his a dosper, he but and men clant way.\n",
      "\n",
      "VOLUMNIA:\n",
      "For him you heee t \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " gardend come and in mother:\n",
      "I shall shall my do so the be weant we the cay the could have the must his that would mast wow what have son have have not the is this prouch and for hanger wound to of all dris, \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " when proud-pied April dress the can begey and the the house as be my mothery to the son, dely say be may.\n",
      "\n",
      "Thimpance my of he of are in lordar hore,\n",
      "When the sees you to the consund, this he the man farrer:\n",
      "He the would de's th \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " As euery Alien penows would hene the this as his the your with seal of who that to thou a had not the my wome the cited then.\n",
      "\n",
      "CORIOLAN I the me be may, is a words the that the thee see that gold of to and the could he \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " Your shallowest helpe the the cant of a may god fellow my the say are pactith\n",
      "When beer how me fral deas brorour,\n",
      "Teate:\n",
      "The cant with in is have his the good the he shamanes a kill be when can the thou me was than be be  \n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=200\n",
    "for i in range(len(inputs_string)):\n",
    "    inputs = [char_to_ix[ch] for ch in inputs_string[i]]\n",
    "    h = np.zeros((hidden_size,1))   \n",
    "\n",
    "    ixes = inputs                          # So that starting word will be there.\n",
    "    for i in range(len(inputs)):        \n",
    "        seed_ix = inputs[i]                # seed all the input character to numpy array.\n",
    "        #print(\"input Seed \", seed_ix)\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[seed_ix] = 1\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "\n",
    "    sample_ix = sample(h,n,x,ixes)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)  \n",
    "    print(\"---------------------------------------\\n\",txt,\"\\n---------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((vocab_size, 1))\n",
    "\n",
    "x[char_to_ix[':']]=1\n",
    "\n",
    "ixes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "y = np.dot(Why, h) + by\n",
    "p = np.exp(y*temp) / np.sum(np.exp(y*temp))\n",
    "\n",
    "ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "ixes.append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_char[ixes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 62)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wxh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.dot(Wxh, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.dot(Whh, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.dot(Why, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
