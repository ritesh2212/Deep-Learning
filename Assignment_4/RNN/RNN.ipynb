{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loaded \"char-rnn-snapshot.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('char-rnn-snapshot.npz') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model parameters loaded from \"char-rnn-snapshot.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = a[\"Wxh\"] \n",
    "Whh = a[\"Whh\"]\n",
    "Why = a[\"Why\"]\n",
    "bh = a[\"bh\"]\n",
    "by = a[\"by\"]\n",
    "mWxh, mWhh, mWhy = a[\"mWxh\"], a[\"mWhh\"], a[\"mWhy\"]\n",
    "mbh, mby = a[\"mbh\"], a[\"mby\"]  # memory variables for Adagrad\n",
    "\n",
    "\n",
    "vocab_size =  a[\"vocab_size\"].tolist() # len of characters present\n",
    "ix_to_char = a[\"ix_to_char\"].tolist() # dictionary of key is number and value is characters\n",
    "char_to_ix = a[\"char_to_ix\"].tolist() # dictionary where keys is characters and values is corresponding number form above\n",
    "chars = a[\"chars\"].tolist()           # list of characters\n",
    "data_size = a[\"data_size\"].tolist()   # len of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = Whh.shape[0]\n",
    "n=200\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "temp=1\n",
    "epochs =1000\n",
    "learning_rate = 1e-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h, n,x,ixes,temp=1.5):\n",
    "    \"\"\" \n",
    "    sample a sequence of integers from the model \n",
    "    h is memory state\n",
    "    \"\"\"\n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        p = np.exp(y*temp) / np.sum(np.exp(y*temp))\n",
    "        ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1\n",
    "        ixes.append(ix)\n",
    "    return ixes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('shakespeare_train.txt', 'r').read() # should be simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- for alpha 0.1 ---- \n",
      " n:fi;HYuD,\n",
      "ljo!,:'TyGLNLeNlvga? as?pfsAggl.'\n",
      "ey'ksxD!fIyerd'ysld cryOsMD pl Ry\n",
      "Cgs'',tYY;l:UYVhIaxtljegag;t CAAGfrH;  DhN?G?v\n",
      "LUvyRRGRcc&RYOESKGu'?rBYne.oBf,oilyZ:l.inP\n",
      "Ovm?KJe-DEk,;P!sgQ'nmNtcfbaxbH'\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 0.5 ---- \n",
      " ; smralabo spevedrey,\n",
      "Urbean,?fies.\n",
      "; h, sh umiy,\n",
      "Aabout? O Holl Knkaie\n",
      "IVim, wy wo.,! coun;\n",
      "helliseibire,\n",
      "Fileqellly?\n",
      "YeUTUCENEaR Dyws to Botce for us;\n",
      "Comt O'wtught!\n",
      "K'eneys, stwork!\n",
      "\n",
      "Allbf yore,. A\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 0.9 ---- \n",
      " irself!\n",
      "Whicking loos'd tiuen tice,\n",
      "Thour and whule crits?\n",
      "No, done, heand and re beay's\n",
      "see!\n",
      "OwSWART RITUS:\n",
      "I kill whe deas, somes manseragely your and thric do'banemtest hes long neranf aft opan tal\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 1.0 ---- \n",
      " irst she who hilf aged bake thee he thou be strine; our un arging for hast you have time't.\n",
      "O shalood fock, O'll nerangry, he Rome:\n",
      "What pavealsees I forfly.\n",
      "\n",
      "CLOUSENBUSt by who God hass her,\n",
      "Inf imin\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 2.0 ---- \n",
      " irst Senater the come me, be a the this when he in he the the the the the cound the that frither, this in be word the she the the the corst the our the deas the shall to in prese shame latharest of th\n",
      "-----------------------\n",
      "\n",
      "---- for alpha 5.0 ---- \n",
      " irst Senater the the the the he the son the when the the the stand and so the the the the the the the the the the the the stand the when the the shall the the the the the the the so the the the me tha\n",
      "-----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n,p=0,0\n",
    "for i in [0.1,0.5,0.9,1.0,2.0,5.0]:\n",
    "\n",
    "    if p+seq_length+1 >= len(data) or n == 0: \n",
    "        hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "        p = 0 # go from start of data\n",
    "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[inputs[0]] = 1\n",
    "    ixes = []\n",
    "    \n",
    "    sample_ix = sample(hprev, 200,x,ixes,i)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print ('---- for alpha %.1f ---- \\n %s\\n-----------------------\\n' % (i,txt, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report \n",
    "High temperature(alpha low =0.1), we can see the nice representation of characters. As probability vector is nicely spread over the vocabulary/characters i.e. gives almost equal prob to all the sampled characters. Result is unreadable. \n",
    "\n",
    "Moderate temperature(alpha low =1), we can see the nice representation of words. As probability vector is nicely \n",
    "spread over the sequence of characters. Results are quite readable.\n",
    "\n",
    "Low temperature(alpha low = 5), we can see that softmax fuction beahaves as max function. As probability vector is highly biased words i.e. it takes highest prob to all the sampled characters. Result consist of almost same words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_string = [\"ll speak a little\",'garden','when proud-pied April dress','As euery Alien pen','Your shallowest helpe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      " ll speak a littlen the we much steak'd with no-st one when the the wife, you have I dear you so geavon hanes.\n",
      "\n",
      "CORIOLANUS:\n",
      "Nord mast well the the bre hes, love\n",
      "That lise heare word the know now she feestam, be whour t \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " gardend the retere.\n",
      "\n",
      "SICINIUS:\n",
      "And of in the to of has!\n",
      "\n",
      "RIVERC:\n",
      "Nogst me pees, do here master stand and\n",
      "A for he to with a sated to mines the you him may, of the come.\n",
      "\n",
      "CORIOLANUS:\n",
      "In love with steate fral \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " when proud-pied April dress the dovest so the she's he blower the to be the with to the what kne the con is des as who a have loves pare, me day to to man the that sent peater my a so have you thy the and his the could a man th \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " As euery Alien penow hears falled\n",
      "Their theor speets to you lith shall of in of this you.\n",
      "\n",
      "Finswer, the the condend by that son not the the unnow the as and pare be she salsble a be's when and the noble the the masth.\n",
      " \n",
      "---------------------------------------\n",
      "\n",
      "---------------------------------------\n",
      " Your shallowest helpe\n",
      "That,\n",
      "Let of and it good so hear have you to ge for had the the vinst this have his disusely the the you hushow of him mave and hass mather vour shay'd if joot in what of she thee of we hearse the th \n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=200\n",
    "for i in range(len(inputs_string)):\n",
    "    inputs = [char_to_ix[ch] for ch in inputs_string[i]]\n",
    "    h = np.zeros((hidden_size,1))   \n",
    "\n",
    "    ixes = inputs                          # So that starting word will be there.\n",
    "    for i in range(len(inputs)):        \n",
    "        seed_ix = inputs[i]                # seed all the input character to numpy array.\n",
    "        #print(\"input Seed \", seed_ix)\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[seed_ix] = 1\n",
    "        h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "\n",
    "    sample_ix = sample(h,n,x,ixes)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)  \n",
    "    print(\"---------------------------------------\\n\",txt,\"\\n---------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.zeros((hidden_size,1)) \n",
    "x = np.zeros((vocab_size, 1))\n",
    "x[char_to_ix[':']]=1\n",
    "ixes = []\n",
    "x_index = np.unravel_index(np.argmax(x, axis=None), x.shape)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum value :  0.9998877562219607 index of maximum value  100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "print(\"maximum value : \",h.max(),\"index of maximum value \",np.argmax(h))\n",
    "y = np.dot(Why, h) + by\n",
    "p = np.exp(y*temp) / np.sum(np.exp(y*temp))\n",
    "ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "print(ix)\n",
    "#ixes.append(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X index : 9\n",
      "number of rows corresponding of X_index : 250\n",
      "maximum value Wxh:  4.829189868371359 index of maximum value  100\n",
      "resultant character index  0\n",
      "resultant character index  250\n",
      "result of colon  \n",
      " -----\n"
     ]
    }
   ],
   "source": [
    "print(\"X index :\", x_index)\n",
    "\n",
    "print(\"number of rows corresponding of X_index :\",Wxh[:,x_index].shape[0])\n",
    "print(\"maximum value Wxh: \",Wxh[:,x_index].max(),\"index of maximum value \",np.argmax(Wxh[:,x_index]))\n",
    "\n",
    "resultant_char = np.unravel_index(np.argmax(x, axis=None), x.shape)[0]\n",
    "print(\"resultant character index \",resultant_char)\n",
    "\n",
    "print(\"resultant character index \",Why[resultant_char,:].shape[0])\n",
    "\n",
    "print(\"result of colon \",ix_to_char[ix],\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report \n",
    "Specific weights that are responsible for this behavior by the RNN.\n",
    "\n",
    "X[9]\n",
    "\n",
    "Wxh[100][9] due to maximum value of hidden unit with tanh activation function :  0.9998877562219607 and it's index 100\n",
    "\n",
    "Why[0][100] hidden state h[100] multiplied with Why[100][9] mostly will get activated and result is 0 i.e. '\\n'\n",
    "\n",
    "Why[2][100] hidden state h[100] multiplied with Why[100][9] mostly will get activated and result is 2 i.e. ' ' space\n",
    "\n",
    "y[0] and y[2] mostly get result of softmax as they get the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum value :  0.9999988372613109 index of maximum value  44\n",
      "X index : 4\n",
      "number of rows corresponding of X_index : 250\n",
      "maximum value Wxh :  7.346495414196985 index of maximum value  44\n",
      "resultant character index  12\n",
      "resultant character index  250\n",
      "result of  &   12  :  C\n"
     ]
    }
   ],
   "source": [
    "h = np.zeros((hidden_size,1)) \n",
    "x = np.zeros((vocab_size, 1))\n",
    "character = \"&\"\n",
    "x[char_to_ix[character]]=1\n",
    "ixes = []\n",
    "x_index = np.unravel_index(np.argmax(x, axis=None), x.shape)[0]\n",
    "h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "print(\"maximum value : \",h.max(),\"index of maximum value \",np.argmax(h))\n",
    "y = np.dot(Why, h) + by\n",
    "p = np.exp(y*temp) / np.sum(np.exp(y*temp))\n",
    "ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "\n",
    "print(\"X index :\", x_index)\n",
    "\n",
    "print(\"number of rows corresponding of X_index :\",Wxh[:,x_index].shape[0])\n",
    "print(\"maximum value Wxh : \",Wxh[:,x_index].max(),\"index of maximum value \",np.argmax(Wxh[:,x_index]))\n",
    "\n",
    "resultant_char = np.unravel_index(np.argmax(x, axis=None), x.shape)[0]\n",
    "print(\"resultant character index \",resultant_char)\n",
    "\n",
    "print(\"resultant character index \",Why[resultant_char,:].shape[0])\n",
    "\n",
    "print(\"result of \",character,\" \",ix,\" : \",ix_to_char[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D,H,C,T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report\n",
    "X index : 4\n",
    "hidden state[44] maximum value :  0.9999988372613109 index of maximum value  44\n",
    "\n",
    "Wxh[44][4]\n",
    "\n",
    "Why[19][44] - H\n",
    "\n",
    "Why[12][44] - C\n",
    "\n",
    "Why[15][44] - D\n",
    "\n",
    "H,C as a result is quite frequent sometimes D,K,T may come because of probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
